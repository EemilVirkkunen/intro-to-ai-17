<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to Artificial Intelligence 2017 | Part 5</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

    <link href="../stylesheets/styles-8493e20a.css" rel="stylesheet" />

    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/styles/xcode.min.css">

    <link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.1/cookieconsent.min.css" />

    <link rel="stylesheet" href="//2017-ohjelmointi.github.io/cdn/code-states-visualizer.css" />
    <link rel="stylesheet" href="https://materiaalit.github.io/typonator-cdn/app.css" />

      <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-47575342-7', 'auto');
  ga('send', 'pageview');
</script>

  </head>
  <body>
    <div class="main-wrapper">
      <div class="header-wrapper">
        <div class="browser-support-warning" id="browser-support-warning" style="display: none;">
  Kaikki tämän materiaalin osat eivät välttämättä tuo nykyistä selaintasi. Voisitko harkita vaihtamista <a href="https://www.google.com/chrome/browser/desktop/" target="_blank" rel="noopener">Chrome</a> tai <a href="https://www.mozilla.org/en-US/firefox/new/" target="_blank" rel="noopener">Firefox</a> selaimeen?
  <span class="browser-support-warning__close">Selvä!</span>
</div>


        <nav class="navbar navbar-light bg-white">
  <a class="navbar-brand" href="http://mooc.fi" alt="MOOC" target="_blank" rel="noopener">
    <span class="icon-mooc"></span>
  </a>

  <ul class="nav navbar-nav hidden-md-down">
      <li class="nav-item ">
        <a href="../" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=index.html&gt;')">Introduction</a>
      </li>
      <li class="nav-item ">
        <a href="../part1/" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=part1.html&gt;')">Part 1</a>
      </li>
      <li class="nav-item ">
        <a href="../part2/" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=part2.html&gt;')">Part 2</a>
      </li>
      <li class="nav-item ">
        <a href="../part3/" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=part3.html&gt;')">Part 3</a>
      </li>
      <li class="nav-item ">
        <a href="../part4/" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=part4.html&gt;')">Part 4</a>
      </li>
      <li class="nav-item active">
        <a href="./" class="nav-link" onclick="ga('send', 'event', 'navigation_topic_link', 'click', '#&lt;Middleman::Sitemap::Resource path=part5.html&gt;')">Part 5</a>
      </li>
  </ul>

  <div class="float-xs-right navbar__buttons">
    <div class="dropdown" id="mobile-nav-dropdown">
      <button class="btn btn-secondary dropdown-toggle navbar__mobile-nav-toggle" data-toggle="dropdown">
        <i class="fa fa-bars"></i>
      </button>

      <div class="dropdown-menu">
      </div>
    </div>

    <a href="https://riot.im/app/#/room/#_ircnet_#iai:irc.snt.utwente.nl" target="_blank" rel="noopener" class="btn btn-secondary">
      <span class="hidden-md-down">Chat</span>
      <i class="fa fa-commenting-o hidden-lg-up"></i>
    </a>

    <button class="btn btn-secondary" id="table-of-contents-toggle">
      <span class="hidden-md-down">Table of contents</span>
      <i class="fa fa-ellipsis-h hidden-lg-up"></i>
    </button>

    <button class="btn btn-primary" id="tmc-login-toggle">Log in</button>
  </div>
</nav>

      </div>

      <div class="content-wrapper">
        <div class="container material" id="material">
            <div class="exercise-list">
  <div class="exercise-list__header">
    Exercises
  </div>

  <div class="exercise-list__content" id="exercise-list"></div>

</div>


          <div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">Machine Learning with Weka: MLP (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  Download and install the Weka system on your computer. We've
  prepared a set of instructions to get started and a minitutorial.
  <a href="../part5_ex1/">Click here</a>. You'll also need to
  download the Two Spirals dataset <a href="https://materiaalit.github.io/intro-to-ai-17/files/spirals.arff">here</a>.
</p>

<p>
  Use Weka to train a multilayer perceptron (MLP) to classify the
  Two Spirals data. The class labels are given in the <code>Class</code>
  column whereas the variables <code>A1</code> and <code>A2</code> are
  the x- and y-coordinates which are the input features.</p>

<p>
  Note that using the default settings gives poor results. When
  accuracy is measured using the <b>Percentage split % 66</b>
  setting, the accuracy is 52.9&nbsp;% (36 correct, 32 incorrect
  instances). Click <b>Visualize classification errors</b> and
  let the x- and y-axis be the input variables <code>A1</code> and
  <code>A2</code> respectively. You will be able to see that the
  decision boundary, which is completely bonkers.
</p>

<p>
  Adjust the MLP settings and experiment with different number of
  hidden layers (the parameter <code>hiddenLayers</code> shows the
  number of neurons on each hidden layer, separated by
  colons <code>:</code>), and the number of training iterations
  (<code>trainingTime</code>). You should get classification error
  less than 10&nbsp;%.
</p>


    </div>
  </div>
</div>

<div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">Machine Learning with Weka: more classifiers (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  <ol>
    <li>
      Use Weka to train a nearest neighbor classifier (<b>Lazy/IB1</b>).
    <li>
      Do the same with a decision tree (<b>Trees/J48</b>).
    <li>
      Visualize the decision boundaries and explain why the MLP, 
      nearest neighbor, and decision tree classifiers work or don't work
      in this case.
  </ol>
</p>


    </div>
  </div>
</div>

You will soon find the lecture slides for this part on the <a href="https://courses.helsinki.fi/DATA15001/119123276">course homepage</a>
under Materials.


<h1 class="material-heading">
    Digital Signal Processing

</h1>

<p>
  The topics of this week include two special kinds of data that
  require somewhat specific techniques: digital signals (such as audio
  or images), and natural language.
</p>

<p>
  Next week we will finish the Digital Signal Processing and Robotics
  theme by studying robotics.
</p>

<div class="hint">
  <div class="hint__header">
    <i class="fa fa-info-circle hint__icon"></i>Learning objectives of Part 5
  </div>

  <div class="hint__body">
    
<table class="table">
  <tr>
    <td>
      Theme
    </td>
    <td>
      Objectives (after the course, you ...)
    </td>
  </tr>
  <tr>
    <td>
      Natural language processing
    </td>
    <td>
      <ul>
	<li>can generate sentences from a given context-free grammar
	<li>can parse a sentence using the Cocke-Younger-Kasami algorithm
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      Digital Signal Processing and Robotics
    </td>
    <td>
      <ul>
	<li>can describe the principles of at least one pattern recognition method (e.g., SIFT/SURF)
	<li>can apply at least one pattern recognition method in practice
      </ul>
    </td>
  </tr>
</table>


  </div>
</div>

<h2 class="material-heading">
    Digital signal representations

</h2>

<p>
  Digital image and audio signals represent recordings of natural
  signals in numerical form. For images, the values represent 
  pixel intensities stored in a two-dimensional array. A third
  dimension can be used to store different bands for, e.g.,
  red, green, and blue (RGB). We can also think of the values
  are functions of the x and y coordinates, F(x,y).
</p>

<p>
  <i>Fun fact (but not required for the exam):</i> In the case of
  audio, the signal can be thought to be a signal of time, F(t), but
  other representations such as those that are functions of frequency,
  F(f), are commonly used. The frequency representation is
  particularly well suited for compact representation since frequency
  bands outside the audible range 20 Hz to 20 kHz can be left out
  without observable (to humans) effect.
</p>

<h2 class="material-heading">
    Pattern recognition

</h2>

<p>
  <b>Pattern recognition</b> is a good example of an AI problem
  involving digital signals. It means generally the problem is
  recognizing an object in a signal (typically an image). The task is
  made hard because signals tend to vary greatly depending on external
  conditions such as camera angle, distance, lighting conditions, 
  echo, noise, and differences between recording devices. Therefore
  the signal is practically always different even if it is from the
  same object.
</p>

<p>
  Based on these facts, an essential requirement for successful
  pattern recognition is the extraction of <b>invariant features</b>
  in the signal. Such features are insensitive (or as insensitive as
  possible) to variation in the external conditions, and tend to be
  similar in recordings of the same object. In the lecture slides
  there is a famous photograph of
  an <a href="https://en.wikipedia.org/wiki/Afghan_Girl">Afghan
  girl</a> by Steve McCurry. She was identified based on the unique
  patterns in the iris of the eye. Here the iris is the invariant
  feature, which remains unchanged when a person grows older even if
  their appearance may otherwise change.  The iris is an example of
  invariance, and a metaphor for more general invariance with respect
  to external conditions.
</p>

<h2 class="material-heading">
    SIFT and SURF

</h2>

<p>
  Good examples of commonly used feature extraction techniques for
  image data include Scale-Invariant Feature Transform (SIFT) and
  Speeded-Up Robust Features (SURF). We take a closer look at the
  SURF technique. It can be broken into two or three stages:
  <ol>
    <li>
      <b>Choosing interest points:</b> We identify a set of (x,y)
      points by maximizing the determinant of a so called Hessian
      matrix that characterizes the local intensity variation 
      around the point. The interest points tend to be located
      at "blobs" in the image. (You are not required to decode the
      details of this -- a rough idea is enough.)
    <li>
      <b>Feature descriptors:</b> The intensity variation around each
      interest point is described by a feature descriptor which is a
      64-dimensional vector (array of 64 real values).  In addition,
      the feature has a scale (size) and an orientation (dominant
      direction).
    <li>
      <b>Feature matching:</b> If the problem is to match objects
      between two images, then both of the above tasks are performed
      on both images. We then find pairs of feature descriptors
      (one extracted from image A and the other from image B) that
      are sufficiently close to each other in Euclidean distance.
  </ol>
</p>
<img src="../img/surf-example-mars-c8674a6e.png" width=100%><br><br>

<p>
  Above is an example of detected features: interest point location,
  scale, and orientation shown by the circles, and the type of
  contrast shown by the color, i.e., dark on light background (red) or
  light on dark background (blue).  <i>Image credit:</i> NASA/Jet
  Propulsion Laboratory/University of Arizona. Image from the edge of
  the south polar residual cap on Mars.
</p>

<div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">Pattern recognition A (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  The TMC template for the pattern recognition task implements
  SURF feature extraction and matching. When you run the template,
  you should get the face example presented at the lecture.
</p>

<p>
  The red dots in the images are the locations of the SURF
  interest points. The lines between points in the two images
  represent matches, i.e., pairs of features whose descriptor
  vectors are sufficiently close to each other to be classified as 
  belonging to the same or similar looking object.
</p>

<p>
  Change the files <code>img1.jpg</code> and <code>img2.jpg</code> in
  the <code>example</code> folder to another pair of images, and
  rerun the template. <i>Note:</i> The images must be the same
  height. (Width can be different.)
</p>

<p>
  Try at least five different pairs of images, some of which include
  the same building, person, and/or object. Try to find examples
  where the feature matching works, and examples where it doesn't.
</p>


    </div>
  </div>
</div>


<div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">Pattern recognition B (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  Use the same template as in the previous exercise.
</p>

<p>
  Choose one or more images and do the following modifications (one
  at a time):
  <ul>
    <li> change brightness, contrast, and color balance
    <li> rotate the image
    <li> crop and rescale
    <li> add noise or blur
  </ul>
  Use your favorite image processing tool (iPhote, GIMP, Photoshop, etc).
</p>

<p>
  Does SURF recognize the objects in the image as the same despite
  the alterations?
</p>

<p>
  <i>An alternative (more fun) way:</i> Take multiple photos of the
  same image from slightly different angles, different distances, 
  in different lighting conditions, with occlusion, etc.
  Does SURF recognize the object despite such changes in 
  external conditions?
</p>


    </div>
  </div>
</div>


<h1 class="material-heading">
    Natural Language Processing

</h1>

<p>
  Language is another example of an area where AI has hard time
  considering how easy it feels to us, as humans, to understand
  natural scenes or language. This is probably in part because
  we don't appreciate the hardness of tasks that even a child
  can perform without much apparent practice. (Of course, a
  child actually practices these skills very intensively, and
  in fact, evolution has trained us for millions of years,
  preconditioning our "neural networks" to process information
  in this form.)
</p>

<p>
  The features that make language distinctive and different from
  many other data sources for which we may apply AI techniques 
  include:
  <ol>
    <li>
      Even though language follows an obvious <b>linear structure</b>
      where a piece of text has a beginning and an end, and the words
      inbetween are in a given order, it also has <b>hierarchical</b>
      structures including, e.g.,
      text&ndash;paragraph&ndash;sentence&ndash;word relations,
      where each sentence, for example, forms a separate unit.
    <li>
      Grammar constrains the possible (allowed) expressions in natural
      languages but still leaves room for ambiguity (unlike formal
      languages such as programming languages which must be 
      unambiguous).
    <li>
      Compared to digital signals such as audio or image, natural
      language data is much closer to <b>semantics</b>: the idea
      of a chair has a direct correspondence with the word 'chair'
      but any particular image of a chair will necessarily carry
      plenty of additional information such as the color, size,
      material of the chair and even the lighting conditions, the
      camera angle, etc, which are completely independent of the
      chair itself.
  </ol>
</p>

<h2 class="material-heading">
    Formal languages and grammars

</h2>


<p>
  Natural language processing (NLP) applies many concepts from
  theoretical computer science which are applicable to the study of
  formal languages. A formal language is generally a set of
  strings. For example, the set of valid mathematical expressions is a
  formal language that includes the
  string <code>(1+2)&times;6&ndash;3</code> but not the string
  <code>1+(+&times;5(</code>. A <b>(formal) grammar</b> is a set
  of symbol manipulation rules that enables the generation of the
  valid strings (or "sentences") in the language.
</p>

<p>
  An important subclass of formal languages is <b>context-free
    languages</b>. A context-free language is defined by a
    context-free grammar, which is a grammar with rules of the
    form <code>V&xrarr;w</code>, where <code>V</code> is
    a <b>non-terminal symbol</b>, and <code>w</code> is a sequence of
    non-terminal or <b>terminal symbols</b>.  The context-free nature
    of the rules means that such a rule can be applied independently
    of the surrounding context, i.e., the symbols before or
    after <code>V</code>.
</p>

<p>
  An example will hopefully make the matter clear. Let <code>S</code>
  be a <b>start symbol</b>, which is also the only non-terminal symbol
  in the grammar. Let the set of terminal symbols be <code>()[]</code>.
  The set of rules is given by
<pre>
S &xrarr; SS
S &xrarr;
S &xrarr; (S)
S &xrarr; [S]
</pre>
</p>

<p>
  The language defined by such a grammar is the set of strings that
  can be generated by repeated application of any of the above rules,
  starting with the start symbol <code>S</code>.
</p>

<p>
  For example, the string <code>()</code> can be generated by first
  applying the rule <code>S &xrarr; (S)</code> to the start symbol,
  whereupon we obtain the intermediate string <code>(S)</code>.
  Applying the rule <code>S &xrarr; </code> to the symbol <code>S</code>
  in the intermediate string, to obtain the final outcome
  <code>()</code>.
</p>

<p>
  As another example, the string <code>(())[]</code> also belongs to
  the language. Can you figure out a sequence of rules to generate it
  from the start symbol <code>S</code>? Notice that each application
  of a rule only applies to a single symbol in the intermediate
  string. So for example, if you apply the rule <code>S &xrarr; (S)</code>
  to the intermediate string <code>SS</code>, only one of the symbols
  gets parentheses around it (you are free to choose which one):
  <code>S(S)</code> or <code>(S)S</code>. If you want to apply the
  same rule to both symbols, you can, you just have to apply the same
  rule twice, which gives <code>(S)(S)</code>.
</p>

<p>
  Try working out a sequence of rules to
  obtain <code>(())[]</code>. To check the correct answer, you can
  look at the example solution below but don't look before you've
  tried it by yourself.
</p>

<div class="solution" data-target='collapse'>
  <div class="solution__header">
    <a data-toggle="collapse" class="solution__toggle">
      <i class="fa fa-magic solution__icon"></i>
      <h1 class="solution__heading">Answer (look only
after trying on your own)</h1>

      <i class="fa fa-caret-down solution__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="solution__body">
      
<p>
  Apply the following sequence of rules:
  <ol>
    <li><code>S &xrarr; SS</code> to the start symbol <code>S</code>:
      result <code>SS</code>
    <li><code>S &xrarr; (S)</code> to the first <code>S</code>: result
      <code>(S)S</code>
    <li><code>S &xrarr; (S)</code> to the first <code>S</code>: result
      <code>((S))S</code>
    <li><code>S &xrarr; </code> to the first <code>S</code>: result
      <code>(())S</code>
    <li><code>S &xrarr; [S]</code> to the only <code>S</code>: result
      <code>(())[S]</code>
    <li><code>S &xrarr; </code> to the only <code>S</code>: result
      <code>(())[]</code>
  </ol>
</p>
        

    </div>
  </div>
</div>

<h2 class="material-heading">
    Parsing

</h2>

<p>
  Efficient algorithms for deciding whether a given string belongs to
  a given context-free language exist. They are based on <b>parsing</b>,
  which means the construction of a <b>parse tree</b>. The parse tree
  represents the hierarchical structure of the string. An example parse
  tree is shown below.
</p>
<img src="../img/diagrams/parse-tree-81cb0e66.png" width=37%>

<p>
  In the above tree, the sentence "she eats a fish with a fork"
  has two main components, "she" and the rest. The rest of the
  sentence likewise has two parts, "eats" and "a fist with a fork".
  The interpretation of this parse tree is that the object of eating
  is a fish that has a fork. (A possible but rather unusual scenario
  as fish rarely have forks.)
</p>

<p>
  The above parse tree demonstrates the ambiguity of natural language,
  which is a challenge to AI applications. A potential solution in
  such scenarios is to use the semantics of the words and to 
  attach word-dependent probabilities to different rules. This
  could for instance suggest that the probability of eating something
  with a fork is a more probable construction than a fish that
  has a fork. This method is called <b>lexicalized parsing</b>.
</p>



<h2 class="material-heading">
    CYK algorithm

</h2>

<div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">NLP: CYK algorithm (pencil-and-paper) (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  coming soon...
</p>


    </div>
  </div>
</div>

<h2 class="material-heading">
    Parse trees and ambiguity

</h2>

<h2 class="material-heading">
    Advanced topics in parsing

</h2>

<h2 class="material-heading">
    Applications of NLP

</h2>

<div class="exercise">
  <div class="exercise__header">
    <a data-toggle="collapse" class="exercise__toggle">
      <i class="fa fa-pencil exercise__icon"></i>
      <h1 class="exercise__heading">NLP: Knowledge extraction (1p)</h1>

      <i class="fa fa-caret-down exercise__arrow"></i>
    </a>
  </div>

  <div class="collapse">
    <div class="exercise__body">
      
<p>
  You'll find a template for this exercise in TMC.</p>

<p>
  <ol>
    <li>
      Implement method <code>extractSubject</code> in
      class <code>Extractor</code>. The input will be a parse
      tree of a sentence. You should try to identify the <b>subject</b> of
      the sentence (<i>who/what</i> does something). One heuristic method
      that doesn't always work, but is close enough, is as follows:
      <ol>
	<li>Assume that the root node of the parse tree, S, has
	  children NP (noun phrase) and VP (verb phrase).  If this
	  is not the case, you can skip the sentence and return null.
	<li>Choose the child NP.
	<li>The subject can be assumed to a noun in the NP subtree
	  (see example below). You can identify nouns by the POS-tag
	  which should be either NN, NNP, NNPS, or NNS.
	<li>Use breadth-first search to find the noun closest to the root.<br>
	  <img src="../img/exercises/ex5/parsetree-68893fca.png" width=65%>
      </ol>
<br><br>

      
      The TMC template has tests to verify your solution.<br><br>
    <li>
      Next, implement the following logic in method <code>main</code>
      in class <code>Main</code> using the tools available in class
      <code>NLPUtils</code>: The template has ready-made functionality
      for iterating through all sentences in Franz Kafka's
      <i>The Metamorphosis</i>. Reject all sentences that don't contain
      the word "Gregor".<br><br>
    <li>
      For all remaining sentences, produce a 
      parsing tree. (If the parsing fails, reject the sentence.) Use the
      method you implemented in item 1 to identify the subject of the
      sentence. Print out all sentences where the subject is "Gregor".
      <br><br>
    <li>
      Use the output to find out what Gregor does in a similar spirit
      as this <a href="http://hint.fm/seer/#left=google%20is&right=artificial%20intelligence%20is">cool applet</a>. (No, you <i>don't</i> have to make
      a visualization!)
  </ol>
</p>

<p>
  <i>Hint:</i> In item 2, you can use method <code>contains</code>.

</p>  


    </div>
  </div>
</div>

        </div>
      </div>

      <div class="footer-wrapper">
        <footer class="footer">
  <div>
    This material is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons BY-NC-SA 4.0 License</a>.

  </div>
  <div class="improvement">
    <a href="https://github.com/materiaalit/intro-to-ai-17/issues/new"  target="_blank" rel="noopener">
  <button class='btn btn-primary'>
    <i class="fa fa-exclamation-triangle" aria-hidden="true"></i> Report an error
  </button>
</a>
<a href="https://github.com/materiaalit/intro-to-ai-17/edit/master/source/part5.html.erb" target="_blank" rel="noopener">
  <button class='btn btn-primary'>
    <i class="fa fa-pencil" aria-hidden="true"></i>
 Edit this page
  </button>
</a>
     <a href="https://github.com/materiaalit/intro-to-ai-17" class="footer__github-link" target="_blank" rel="noopener">
      <i class="fa fa-github"></i>
    </a>
  </div>
</footer>

      </div>
    </div>

    <div class="modal fade" id="tmc-login-modal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content">
      <form id="tmc-login-form">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
          <h4 class="modal-title">Log in with your Test My Code Account</h4>
        </div>
        <div class="modal-body">
          <div class="alert alert-info">
            Don't have an account yet? <a href="https://tmc.mooc.fi/user/new" class="alert-link" target="_blank" rel="noopener">Create one!</a>
          </div>

          <div class="alert alert-danger" id="tmc-login-error" style="display: none;"></div>

          <div class="form-group">
            <label>Username</label>
            <input type="text" id="tmc-login-username" class="form-control" placeholder="Username"/>
          </div>

          <div class="form-group">
            <label>Password</label>
            <input type="password" id="tmc-login-password" class="form-control" placeholder="Password"/>
          </div>

          <div class="form-group">
            <label>Course</label>

            <div class="form-check">
              <label class="form-check-label">
                <input type="radio" class="form-check-input" name="tmcLoginCourse" value="intro-to-ai-17" checked>
                 Introduction to Artificial Intelligence 2017 (intro-to-ai-17)
              </label>
            </div>

            <small class="form-text text-muted">
              Course selection may affect the contents of the material.
            </small>
          </div>
        </div>
        <div class="modal-footer">
          <a class="btn btn-secondary" data-dismiss="modal">Close</a>
          <button type="submit" class="btn btn-primary">Log in</button>
        </div>
      </form>
    </div>
  </div>
</div>


    <div class="table-of-contents-layer" id="table-of-contents-layer">
</div>

<div class="table-of-contents" id="table-of-contents">
  <h1 class="table-of-contents__heading">
    Table of Contents
  </h1>

  <div class="table-of-contents__content">
    <ul id="table-of-contents-list"></ul>
  </div>
</div>


    <script>
  window._QUIZNATOR_ENABLED = true;
</script>

<script src="https://quiznator.herokuapp.com/javascripts/plugin-loader.min.js"></script>


    <script src="https://code.jquery.com/jquery-3.1.1.min.js"
	    integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="
	    crossorigin="anonymous"></script>

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    <script>
      window.SD_SHOW_SURVEY = ['part6', 'part7'].indexOf(window.location.pathname.replace(/\//g,'')) >= 0;
    </script>

    <script src="../javascripts/scripts-e606b1e7.js"></script>

    <script src="https://use.fontawesome.com/ed2f73836b.js"></script>

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/highlight.min.js"></script>

    <script>hljs.initHighlightingOnLoad();</script>

    <script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.1/cookieconsent.min.js"></script>
    <script src='//cdnjs.cloudflare.com/ajax/libs/diff_match_patch/20121119/diff_match_patch.js'></script>

    <script>window.cookieconsent.initialise({"palette":{"popup":{"background":"#000"},"button":{"background":"#f1d600"}}});</script>

    <script src='//2017-ohjelmointi.github.io/cdn/code-states-visualizer.js'></script>
    <script src='https://materiaalit.github.io/typonator-cdn/app.js'></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        window.initCodeStatesVisualizer();
        window.initTyponator();
      });
    </script>
  </body>
</html>
